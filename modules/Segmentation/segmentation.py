#!/usr/bin/env python3

""" 
segmentation.py: Módulo de segmentación.
"""


import numpy as np
import cv2
import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import time

from segment_anything import SamAutomaticMaskGenerator, sam_model_registry
from modules.Module3D.depth_estimation import estimate

LIGHT_PURPLE = (213, 184, 255)
DARK_BLUE = (1, 1, 122)

def showSAM(img, masks):
    """Show SAM segmentation over original image

    Parameters
    ----------
    img : array_like, shape (N,2)
        Original image
    masks : list
        list of segmentation masks generated by SAM

    """

    fig = plt.figure(figsize=(20,20))
    plt.imshow(img)

    if len(masks) == 0:
        return
    sorted_anns = sorted(masks, key=(lambda x: x['area']), reverse=True)
    ax = plt.gca()
    ax.set_autoscale_on(False)
    for ann in sorted_anns:
        m = ann['segmentation']
        img = np.ones((m.shape[0], m.shape[1], 3))
        color_mask = np.random.random((1, 3)).tolist()[0]
        for i in range(3):
            img[:,:,i] = color_mask[i]
        ax.imshow(np.dstack((img, m*0.5)))

    plt.axis('off')
    plt.show()



def binarySegmentationDepth(points):
    """Get waterbody segmentation using depth estimation

    Parameters
    ----------
    points : array_like, shape (N,3)
        Array containing the set of points in 3D

    Returns
    -------
    img : array_like,
        Image with the waterbody segmentation

    """
    nrows,ncols = points.shape
    
    img = np.zeros((nrows,ncols,3), dtype=np.int32)
    
    for i in range(nrows):
        for j in range(ncols):
            if points[i,j] > 0.55:
                img[i,j] = LIGHT_PURPLE
            else:
                img[i,j] = DARK_BLUE
    
    return img

def showBinarySegmentationDepth(image_path):
    """Show waterbody segmentation using depth estimation

    Parameters
    ----------
    image_path : str
        Image path

    Returns
    -------
    img : array_like,
        Image with the waterbody segmentation

    """

    img = cv2.imread(image_path)
    nrows,ncols,_ = img.shape

    start = time.time()

    # Estimate depth for image
    points = estimate(image_path)

    mask = binarySegmentationDepth(points).astype(np.uint8)

    # Resize mask
    mask_resized = cv2.resize(mask, (ncols,nrows), interpolation = cv2.INTER_AREA)

    end = time.time()
    print('Execution time:',end-start)

    plt.imshow(mask_resized)

    legend_data = [
        [127,list(LIGHT_PURPLE),"agua"],
        [126,list(DARK_BLUE),"escena"]
    ]
    handles = [
        Rectangle((0,0),1,1, color = [v/255 for v in c]) for k,c,n in legend_data
    ]
    labels = [n for k,c,n in legend_data]


    plt.grid(False)
    plt.axis('off')
    plt.legend(handles,labels)
    plt.show()

    # Show image
    # cv2.imshow('Depth-based segmentation', cv2.cvtColor(mask_resized, cv2.COLOR_BGR2RGB))
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()
    
    return mask_resized



def floatingSegmentation(binary_mask):
    """Get floating objects segmentation

    Parameters
    ----------
    binary_mask : array_like
        Image with binary segmentation.

    Returns
    -------
    img : array_like,
        Image with the floating objects segmentation

    """
    # Convert to gray scale
    gray = cv2.cvtColor(binary_mask, cv2.COLOR_RGB2GRAY)

    # Find Canny edges
    edged = cv2.Canny(gray, 30, 200)

    # Taking a matrix of size 5 as the kernel
    kernel = np.ones((3, 3), np.uint8)
    edged = cv2.dilate(edged, kernel, iterations=1)
    
    # Finding Contours
    contours, hierarchy = cv2.findContours(edged, 
        cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)
    print(len(contours))
    
    result = binary_mask.copy()

    for i in range(len(contours)):

        # Calculate contour's area
        area = cv2.contourArea(contours[i])

        # Check if contour is closed
        if hierarchy[0][i][2] > 0:

            # Draw and fill contour 
            cv2.drawContours(result, [contours[i]], 0, (0,128,90), -1)

    return result

def showFloatingSegmentation(binary_mask):
    """Show floating objects segmentation

    Parameters
    ----------
    binary_mask : array_like
        Image with binary segmentation.

    Returns
    -------
    img : array_like,
        Image with the floating objects segmentation

    """

    result = floatingSegmentation(binary_mask)

    plt.imshow(result)

    legend_data = [
        [127,list(LIGHT_PURPLE),"agua"],
        [126,list(DARK_BLUE),"escena"],
        [125,list([0,128,90]),"flotante"]
    ]
    handles = [
        Rectangle((0,0),1,1, color = [v/255 for v in c]) for k,c,n in legend_data
    ]
    labels = [n for k,c,n in legend_data]


    plt.grid(False)
    plt.axis('off')
    plt.legend(handles,labels)
    plt.show()

    # Show image
    # cv2.imshow('Floating objects segmentation', cv2.cvtColor(result, cv2.COLOR_BGR2RGB))
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()
    
    return result



def segmentationSAM(img):
    """Get the segmentation of an image with SAM

    Parameters
    ----------
    img : array_like, shape (rows,cols,3)
        Image to segment

    Returns
    -------
    masks : list of masks
        List of segmentation masks found by SAM in the image where each mask is a dictionary with the following fields:
            - segmentation : the mask
            - area : the area of the mask in pixels
            - bbox : the boundary box of the mask in XYWH format
            - predicted_iou : the model's own prediction for the quality of the mask
            - point_coords : the sampled input point that generated this mask
            - stability_score : an additional measure of mask quality
            - crop_box : the crop of the image used to generate this mask in XYWH format
    """

    sam = sam_model_registry["vit_h"](checkpoint="modules/vit_h.pth")
    mask_generator = SamAutomaticMaskGenerator(
        model=sam,
        points_per_side=32
    )
    masks = mask_generator.generate(img)

    return masks



def segmentationFinal(image_path):
    """Get the segmentation combining SAM with depth estimation. If possible, the function returns an object segmentation

    Parameters
    ----------
    image_path : str
        Image path

    Returns
    -------
    binary_mask : array_like
        Image with binary segmentation. If binary mask calculated with SAM does not segment water properly, depth based segmentation will be used.
    color_mask : array_like
        Image with object segmentation. If binary mask calculated with SAM does not segment water properly, color_mask will be None
    """


    def getIntersectAndUnion(merged, segment_index, thresh):
        """Calculates intersection and union values between 'segment' and 'thresh'"""

        intersection = 0
        union = 0

        
        # Calculate intersection and union values
        for i in range(merged.shape[0]):
            for j in range(merged.shape[1]):
                if merged[i,j] == segment_index+1:
                    if thresh[i,j,:].tolist() == list(LIGHT_PURPLE):
                        intersection += 1
                    union += 1

        return intersection, union
    
    start = time.time()
    
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    nrows_img, ncols_img, _ = img.shape

    # Estimate depth for image
    depth = estimate(image_path)

    # Segmentation with depth
    thresh = binarySegmentationDepth(depth)
    thresh = cv2.resize(thresh, (ncols_img,nrows_img), interpolation = cv2.INTER_LINEAR_EXACT)
    
    
    # Count water pixels 
    water = 0
    for i in range(nrows_img):
        for j in range(ncols_img):
            if thresh[i,j,:].tolist() == list(LIGHT_PURPLE):
                water += 1
    water_percent = water/(nrows_img*ncols_img)
    
    # Get SAM segmentation
    masks = segmentationSAM(img)
    masks = sorted(masks, key=(lambda x: x['area']))

    new_areas = np.zeros(len(masks)).tolist()

    # Merge masks
    merged = np.zeros((nrows_img, ncols_img),dtype=int)
    for i in range(merged.shape[0]):
        for j in range(merged.shape[1]):
            for m in range(len(masks)):
                if masks[m]['segmentation'][i,j]:
                    merged[i,j] = m+1
                    new_areas[m] += 1
                    break
    
    # Select biggest segment as water
    water_segment_index = np.argmax(np.array(new_areas))
    
    intersection, union = getIntersectAndUnion(merged, water_segment_index, thresh)
    
    # Check if selected water segment has a good "intersect over union" value
    while (intersection/union) < 0.5:
        # "Intersect over union" value is not good enough. Search for another water segment
        del new_areas[water_segment_index]
        if len(new_areas) == 0:
            print('Intersection over union is not good enough for any mask. Segmentation based on depth estimation will be used')
            end = time.time()
            print('Execution time:',end-start)
            return thresh, None
        water_segment_index = np.argmax(np.array(new_areas))
        
        intersection, union = getIntersectAndUnion(merged, water_segment_index, thresh)
        
    union += (water - intersection)

    color_mask = img.copy()
    binary_mask = img.copy()
    
        
    # Defining random colors
    colors = []
    for i in range(len(masks)):
        for j in range(3):
            colors.append(list(np.random.choice(range(255),size=3)))
    
    water = 0

    # Create binary and color masks
    for i in range(merged.shape[0]):
        for j in range(merged.shape[1]):
            if merged[i,j] == water_segment_index+1:
                color_mask[i,j] = LIGHT_PURPLE
                binary_mask[i,j] = LIGHT_PURPLE
                water +=1
            else:  
                color_mask[i,j] = colors[merged[i,j]]
                binary_mask[i,j] = DARK_BLUE

    water_percent_SAM = water/(merged.shape[0]*merged.shape[1])

    if water_percent_SAM/water_percent < 0.5:
        print('No se ha encontrado una máscara binaria mejor. Se utiliza la calculada a partir de la estimación de profundidad')
        end = time.time()
        print('Execution time:',end-start)
        return thresh, None
    
    end = time.time()
    print('Execution time:',end-start)
    
    return binary_mask, color_mask





def binarySegmentationSuperpixels(img):
    """Get binary segmentation based on HSV range colors using superpixels

    Parameters
    ----------
    img : array_like, shape (rows,cols,3)
        Image to segment

    Returns
    -------
    mask : array_like
        Image with binary segmentation.
    """

    # Convert to HSV color space
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    hsv_image= cv2.cvtColor(img, cv2.COLOR_RGB2HSV)

    # SEEDS parameters
    height,width,channels = hsv_image.shape
    num_iterations = 500
    prior = 5
    num_superpixels = 800
    num_levels = 20
    num_histogram_bins = 5


    seeds = cv2.ximgproc.createSuperpixelSEEDS(width, height, channels, num_superpixels, num_levels, prior, num_histogram_bins)
    color_img = np.zeros((height,width,3), np.uint8)
    color_img[:] = (0, 0, 255)

    # Iterate until segmentation is done
    seeds.iterate(img, num_iterations)

    # Get the labels for each pixel
    labels = seeds.getLabels()

    superpixel_mask = seeds.getLabelContourMask(False)

    # Stitch foreground & background together
    mask_inv = cv2.bitwise_not(superpixel_mask)
    result_bg = cv2.bitwise_and(img, img, mask=mask_inv)
    result_fg = cv2.bitwise_and(color_img, color_img, mask=superpixel_mask)
    result = cv2.add(result_bg, result_fg)

    # Create an empty image to draw the superpixel segments
    output = np.zeros_like(img)

    # Define HSV blue range
    lower_blue = np.array([87,150,150])
    upper_blue= np.array([130,255,255])

    # Define HSV white range
    lower_white = np.array([0,0,220])
    upper_white = np.array([180,255,255])

    # Loop over each superpixel and color it in either light purple or dark blue
    for i in range(num_superpixels):
        mask = labels == i
        superpixel_color = np.mean(hsv_image[mask], axis=0)  # Calcula la media del color del superpíxel

        if np.all(superpixel_color >= lower_blue) and np.all(superpixel_color <= upper_blue):
            output[mask] = LIGHT_PURPLE
        elif np.all(superpixel_color >= lower_white) and np.all(superpixel_color <= upper_white):
            output[mask] = LIGHT_PURPLE
        else:
            output[mask] = DARK_BLUE

    # Convert output from BGR to RGB for visualization
    # output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)
    output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)

    # cv2.imshow('superpixels', result)
    # cv2.waitKey(0)

    return output

def showBinarySegmentationSuperpixels(image_path):
    """Shows binary segmentation based on HSV range colors using superpixels

    Parameters
    ----------
    image_path : str
        Image path

    Returns
    -------
    output : array_like
        Image with binary segmentation.
    """

    # Read image path
    img = cv2.imread(image_path)
    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    start = time.time()
    mask = binarySegmentationSuperpixels(img)
    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)
    end = time.time()

    print('Execution time:',end-start)

    plt.imshow(mask)

    legend_data = [
        [127,list(LIGHT_PURPLE),"agua"],
        [126,list(DARK_BLUE),"escena"]
    ]
    handles = [
        Rectangle((0,0),1,1, color = [v/255 for v in c]) for k,c,n in legend_data
    ]
    labels = [n for k,c,n in legend_data]


    plt.grid(False)
    plt.axis('off')
    plt.legend(handles,labels)
    plt.show()

    # Show image
    # cv2.imshow('Superpixel segmentation', cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()

    return mask



def showSegmentation(binary_mask, color_mask=None):
    """Shows both binary and object segmentation images.

    Parameters
    ----------
    binary_mask : array_like, shape (nrows, ncols, 3)
        Binary segmentation mask
    color_mask : array_like, shape (nrows, ncols, 3)
        Object segmentation mask. If color_mask is None, object segmentation is not shown

    """

    # Resize mask
    nrows, ncols,_ = binary_mask.shape
    binaryMask_resized = cv2.resize(binary_mask, (ncols,nrows), interpolation = cv2.INTER_AREA)



    if color_mask is None:
        ncols_plot = 1

    else:
        colorMask_resized = cv2.resize(color_mask, (ncols,nrows), interpolation = cv2.INTER_AREA)
        ncols_plot = 2

    legend_data = [
        [127,list(LIGHT_PURPLE),"agua"],
        [126,list(DARK_BLUE),"escena"]
    ]
    handles = [
        Rectangle((0,0),1,1, color = [v/255 for v in c]) for k,c,n in legend_data
    ]
    labels = [n for k,c,n in legend_data]


    # Plot segmentation
    fig = plt.figure(figsize=plt.figaspect(0.5))
        
    # ===========================
    # First subplot (binary mask)
    # ===========================
    # set up the axes for the first plot
    ax = fig.add_subplot(1, ncols_plot, 1)
    ax.set_title('Binary segmentation')
    ax.imshow(binaryMask_resized)

    ax.grid(False)
    ax.axis('off')
    ax.legend(handles,labels)

    if color_mask is not None:

        # ===========================
        # Second subplot (color mask)
        # ===========================
        # set up the axes for the second plot
        ax = fig.add_subplot(1, ncols_plot, 2)
        ax.set_title('Object segmentation')
        ax.imshow(colorMask_resized)

        ax.grid(False)
        ax.axis('off')
        ax.legend([handles[0]],[labels[0]])
    
    
    plt.show()


def evaluate(eval_path, mask):
    """Evaluate 'mask' with mask located in 'eval_path'. The function calculates TP, FP, TN, FN. Water pixels must be labeled as RGB (0,0,0) in mask located in 'eval_path'.

    Parameters
    ----------
    eval_path : str
        Path to evaluation mask
    mask : array_like
        Segmentation mask to evaluate

    Returns
    -------
    TP : int
        True positives
    FP : int
        False positives
    TN : int
        True negatives
    FN : int
        False negatives

    """

    # mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)

    # Load evaluation mask
    eval_mask = cv2.imread(eval_path)
    eval_mask = cv2.cvtColor(eval_mask, cv2.COLOR_BGR2RGB)

    c = (0,0,0) # Black
    indices = np.where(np.all(eval_mask == c, axis=-1))
    water_GT = list(zip(indices[0], indices[1]))
    
    indices = np.where(np.any(eval_mask != c, axis=-1))
    not_water_GT = list(zip(indices[0], indices[1]))

    TP = 0
    FP = 0
    TN = 0
    FN = 0

    for p in water_GT:
        if mask[p[0],p[1],:].tolist() == list(LIGHT_PURPLE):
            TP +=1 
        else:
            FN +=1
    
    for p in not_water_GT:
        if mask[p[0],p[1],:].tolist() != list(LIGHT_PURPLE):
            TN +=1
        else:
            FP +=1
    
    return TP, FP, TN, FN