#!/usr/bin/env python3

""" 
segmentation.py: Módulo de segmentación.
"""


import numpy as np
import cv2
import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import time
from sklearn.cluster import DBSCAN

from segment_anything import SamAutomaticMaskGenerator, sam_model_registry
from modules.Module3D.depth_estimation import estimate

LIGHT_PURPLE = (213, 184, 255)
DARK_BLUE = (1, 1, 122)

def showSAM(img, masks):
    """Show SAM segmentation over original image

    Parameters
    ----------
    img : array_like, shape (N,2)
        Original image
    masks : list
        list of segmentation masks generated by SAM

    """

    fig = plt.figure(figsize=(20,20))
    plt.imshow(img)

    masks

    if len(masks) == 0:
        return
    sorted_anns = sorted(masks, key=(lambda x: x['area']), reverse=True)
    ax = plt.gca()
    ax.set_autoscale_on(False)
    for ann in sorted_anns:
        m = ann['segmentation']
        img = np.ones((m.shape[0], m.shape[1], 3))
        color_mask = np.random.random((1, 3)).tolist()[0]
        for i in range(3):
            img[:,:,i] = color_mask[i]
        ax.imshow(np.dstack((img, m*0.5)))

    plt.axis('off')
    plt.show()



def binarySegmentationDepth(depth):
    """Get waterbody binary segmentation using depth estimation threshold

    Parameters
    ----------
    depth : numpy array, shape (nrows,ncols)
        Depth estimation

    Returns
    -------
    img : array_like,
        Image with the waterbody binary segmentation

    """
    nrows,ncols = depth.shape
    
    img = np.zeros((nrows,ncols,3), dtype=np.int32)
    
    for i in range(nrows):
        for j in range(ncols):
            if depth[i,j] > 0.55:
                img[i,j] = LIGHT_PURPLE
            else:
                img[i,j] = DARK_BLUE
    
    return img

def showBinarySegmentationDepth(image_path):
    """Show waterbody segmentation using depth estimation

    Parameters
    ----------
    image_path : str
        Image path

    Returns
    -------
    img : array_like,
        Image with the waterbody segmentation

    """

    img = cv2.imread(image_path)
    nrows,ncols,_ = img.shape

    start = time.time()

    # Estimate depth for image
    points = estimate(image_path)

    mask = binarySegmentationDepth(points).astype(np.uint8)

    # Resize mask
    mask_resized = cv2.resize(mask, (ncols,nrows), interpolation = cv2.INTER_AREA)

    end = time.time()
    print('Execution time:',end-start)

    plt.imshow(mask_resized)

    legend_data = [
        [127,list(LIGHT_PURPLE),"water"],
        [126,list(DARK_BLUE),"scene"]
    ]
    handles = [
        Rectangle((0,0),1,1, color = [v/255 for v in c]) for k,c,n in legend_data
    ]
    labels = [n for k,c,n in legend_data]


    # Show image
    plt.grid(False)
    plt.axis('off')
    plt.legend(handles,labels)
    plt.show()
    
    return mask_resized





def floatingSegmentation2(binary_mask):
    """Get floating objects segmentation

    Parameters
    ----------
    binary_mask : array_like
        Image with binary segmentation.

    Returns
    -------
    img : array_like,
        Image with the floating objects segmentation

    """

    def generate_line(start, end):
        """Generate a line of points between two points.

        Parameters
        ----------
        start : tuple
            The start point of the line.
        end : tuple
            The end point of the line.

        Returns
        -------
        line : list
            The line of points.
        """
        # Bresenham's line algorithm
        x0, y0 = start
        x1, y1 = end
        line = []
        dx = abs(x1 - x0)
        dy = abs(y1 - y0)
        sx = 1 if x0 < x1 else -1
        sy = 1 if y0 < y1 else -1
        err = dx - dy

        while True:
            line.append((x0, y0))
            if x0 == x1 and y0 == y1:
                break
            e2 = 2 * err
            if e2 > -dy:
                err -= dy
                x0 += sx
            if e2 < dx:
                err += dx
                y0 += sy

        line = np.expand_dims(line, axis=1)

        return line
    
    # Add a border to the image (top, left and right)

    # Convert to gray scale
    gray = cv2.cvtColor(binary_mask.astype(np.uint8), cv2.COLOR_RGB2GRAY)

    # Find Canny edges
    edged = cv2.Canny(gray, 30, 200)

    # Taking a matrix of size 5 as the kernel
    kernel = np.ones((2, 2), np.uint8)
    edged = cv2.dilate(edged, kernel, iterations=1)
    
    # Finding Contours
    contours, hierarchy = cv2.findContours(edged, 
        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    result = binary_mask.copy()

    # Convert contours tuple to list
    contours_list = [np.array(contour) for contour in contours]

    tolerance = 5  # Adjust this value as needed
    cluster_distance = 10  # Adjust this value as needed

    epsilon = 0.1*cv2.arcLength(contours_list[0],True)
    lines = {}

    for i in range(len(contours_list)):
        # Simplify contour
        # contours_list[i] = cv2.approxPolyDP(contours_list[i], epsilon, True)

        # Check if contour is close to the top, left or right border
        boundary_points = []
        for point in contours_list[i]:
            if point[0][0] == 0 or point[0][1] == 0 or point[0][0] == binary_mask.shape[1]-1:
                boundary_points.append(point[0])
        if i == 0:
            print('Boundary points:',boundary_points)

        # Find the two nearest points on the boundary that have the largest gap between them
        if len(boundary_points) > 0:
            boundary_points.sort(key=lambda x: x[0])  # Sort points by x-coordinate
            max_gap = 0
            points_with_max_gap = (boundary_points[0], boundary_points[0])
            for j in range(1, len(boundary_points)):
                gap = np.linalg.norm(boundary_points[j] - boundary_points[j-1])
                if gap > max_gap:
                    max_gap = gap
                    points_with_max_gap = (boundary_points[j-1], boundary_points[j])

            # Generate a line between the points with the largest gap
            line = generate_line(tuple(points_with_max_gap[0]), tuple(points_with_max_gap[1]))
            lines[i] = line
            if i == 0:
                print('Contour0',contours_list[0])
                print('Line',i,':',line)

            hierarchy[0][i][2] = -1  # Mark contour as closed

        # Check if contour is closed
        if hierarchy[0][i][2] == -1:
            # print('Contour',i,'is closed')
            # Concatenate line with contour when drawing contour
            if i in lines:
                contour_with_line = np.concatenate((contours_list[i], lines[i]), axis=0)
                if i == 0:
                    print(contour_with_line)
                cv2.drawContours(result, [contour_with_line], 0, (0,128,90), thickness=cv2.FILLED)
            else:
                cv2.drawContours(result, [contours_list[i]], 0, (0,128,90), thickness=cv2.FILLED)

    # Black background
    
    # aux = np.zeros((binary_mask.shape[0],binary_mask.shape[1],3), dtype=np.uint8)

    #plot lines[6] in aux
    # cv2.drawContours(aux, [contours_list[0]], 0, (0,128,90), -1)
    # cv2.imshow('Contours', aux)
    # cv2.waitKey(0)
    # cv2.drawContours(aux, [lines[0]], 0, (0,128,90), -1)
    # cv2.imshow('Contours', aux)
    # cv2.waitKey(0)
    # contour_with_line = np.concatenate((contours_list[0], lines[0]), axis=0)
    # cv2.drawContours(aux, [contour_with_line], 0, (0,128,90), -1)
    # cv2.imshow('Contours', aux)
    # cv2.waitKey(0)


    # show first contour
    # cv2.drawContours(aux, [contours_list[5]], 0, (0,128,90), -1)
    # cv2.imshow('Contours', aux)
    # cv2.waitKey(0)
    # contour_with_line = np.concatenate((contours_list[6], lines[6]), axis=0)
    # cv2.drawContours(aux, [contour_with_line], 0, (0,128,90), -1)
    # cv2.imshow('Contours', aux)
    # cv2.waitKey(0)
    # cv2.drawContours(aux, [contours_list[7]], 0, (0,128,90), -1)
    # cv2.imshow('Contours', aux)
    # cv2.waitKey(0)

    # for i in range(len(contours_list)):
    #     cv2.drawContours(aux, [contours_list[i]], 0, (0,128,90), -1)
    #     cv2.imshow('Contours', aux)
    #     cv2.waitKey(0)
    #     cv2.destroyAllWindows()
    
    # print(contours_list[6])
                
    cv2.imshow('Contours', result)
            
    return result

def floatingSegmentation(binary_mask):
    """Get floating objects segmentation

    Parameters
    ----------
    binary_mask : array_like
        Image with binary segmentation.

    Returns
    -------
    img : array_like,
        Image with the floating objects segmentation
    """

    def is_floating(component_mask):
        """Check if a component is a floating object

        Parameters
        ----------
        component_mask : array_like
            Binary mask of the component.

        Returns
        -------
        bool
            True if the component is a floating object, False otherwise.
        """
        if np.sum(component_mask[-1, :]) == 0:
            return True
        else:
            return False

    # Convert the binary mask to grayscale if it's not already
    gray_img = cv2.cvtColor(binary_mask, cv2.COLOR_BGR2GRAY)

    # show binary mask
    # cv2.imshow('Contours', binary_mask)
    # cv2.waitKey(0)

    # Apply a 7x7 Gaussian blur
    blurred = cv2.GaussianBlur(gray_img, (7, 7), 0)

    # Applying threshold 
    threshold = cv2.threshold(blurred, 0, 255, 
    cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]

    # Apply the Component analysis function 
    analysis = cv2.connectedComponentsWithStats(threshold, 
                                                4,
                                                cv2.CV_32S) 
    (totalLabels, label_ids, values, centroid) = analysis 

    # Use binary_mask as the output image
    output = binary_mask.copy()

    # Loop through each component 
    for i in range(1, totalLabels): 
        # If the component is a floating point
        if is_floating(analysis[1] == i):
            # Create the mask
            mask = (analysis[1] == i).astype("uint8")
            # Apply the mask to the appropriate channels
            output[mask == 1] = (0, 128, 90)

    # cv2.imshow("Filtered Components", output) 
    # cv2.waitKey(0)

    return output
    

def showFloatingSegmentation(binary_mask):
    """Show floating objects segmentation

    Parameters
    ----------
    binary_mask : array_like
        Image with binary segmentation.

    Returns
    -------
    img : array_like,
        Image with the floating objects segmentation

    """

    result = floatingSegmentation(binary_mask)

    plt.imshow(result)

    legend_data = [
        [127,list(LIGHT_PURPLE),"water"],
        [126,list(DARK_BLUE),"scene"],
        [125,list([0,128,90]),"floating"]
    ]
    handles = [
        Rectangle((0,0),1,1, color = [v/255 for v in c]) for k,c,n in legend_data
    ]
    labels = [n for k,c,n in legend_data]


    # Show image
    plt.grid(False)
    plt.axis('off')
    plt.legend(handles,labels)
    plt.show()

    
    return result



def segmentationSAM(img):
    """Get the segmentation of an image with SAM

    Parameters
    ----------
    img : array_like, shape (rows,cols,3)
        Image to segment

    Returns
    -------
    masks : list of masks
        List of segmentation masks found by SAM in the image where each mask is a dictionary with the following fields:
            - segmentation : the mask
            - area : the area of the mask in pixels
            - bbox : the boundary box of the mask in XYWH format
            - predicted_iou : the model's own prediction for the quality of the mask
            - point_coords : the sampled input point that generated this mask
            - stability_score : an additional measure of mask quality
            - crop_box : the crop of the image used to generate this mask in XYWH format
    """

    sam = sam_model_registry["vit_b"](checkpoint="modules/vit_b.pth")
    mask_generator = SamAutomaticMaskGenerator(
        model=sam,
        points_per_side=32
    )
    masks = mask_generator.generate(img)

    return masks



def binarySegmentationSuperpixels(img):
    """Get binary segmentation based on HSV range colors using superpixels

    Parameters
    ----------
    img : array_like, shape (rows,cols,3)
        Image to segment

    Returns
    -------
    mask : array_like
        Image with binary segmentation.
    """

    # Convert to HSV color space
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    hsv_image= cv2.cvtColor(img, cv2.COLOR_RGB2HSV)

    # SEEDS parameters
    height,width,channels = hsv_image.shape
    num_iterations = 500
    prior = 5
    num_superpixels = 800
    num_levels = 20
    num_histogram_bins = 5


    seeds = cv2.ximgproc.createSuperpixelSEEDS(width, height, channels, num_superpixels, num_levels, prior, num_histogram_bins)
    color_img = np.zeros((height,width,3), np.uint8)
    color_img[:] = (0, 0, 255)

    # Iterate until segmentation is done
    seeds.iterate(img, num_iterations)

    # Get the labels for each pixel
    labels = seeds.getLabels()

    superpixel_mask = seeds.getLabelContourMask(False)

    # Stitch foreground & background together
    mask_inv = cv2.bitwise_not(superpixel_mask)
    result_bg = cv2.bitwise_and(img, img, mask=mask_inv)
    result_fg = cv2.bitwise_and(color_img, color_img, mask=superpixel_mask)
    result = cv2.add(result_bg, result_fg)

    # Create an empty image to draw the superpixel segments
    output = np.zeros_like(img)

    # Define HSV blue range
    lower_blue = np.array([87,150,150])
    upper_blue= np.array([130,255,255])

    # Define HSV white range
    lower_white = np.array([0,0,220])
    upper_white = np.array([180,255,255])

    # Loop over each superpixel and color it in either light purple or dark blue
    for i in range(num_superpixels):
        mask = labels == i
        superpixel_color = np.mean(hsv_image[mask], axis=0)  # Calcula la media del color del superpíxel

        if np.all(superpixel_color >= lower_blue) and np.all(superpixel_color <= upper_blue):
            output[mask] = LIGHT_PURPLE
        elif np.all(superpixel_color >= lower_white) and np.all(superpixel_color <= upper_white):
            output[mask] = LIGHT_PURPLE
        else:
            output[mask] = DARK_BLUE

    # Convert output from BGR to RGB for visualization
    output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)

    # cv2.imshow('superpixels', result)
    # cv2.waitKey(0)

    return output

def showBinarySegmentationSuperpixels(image_path):
    """Shows binary segmentation based on HSV range colors using superpixels

    Parameters
    ----------
    image_path : str
        Image path

    Returns
    -------
    output : array_like
        Image with binary segmentation.
    """

    # Read image path
    img = cv2.imread(image_path)
    start = time.time()
    mask = binarySegmentationSuperpixels(img)
    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)
    end = time.time()

    print('Execution time:',end-start)

    plt.imshow(mask)

    legend_data = [
        [127,list(LIGHT_PURPLE),"water"],
        [126,list(DARK_BLUE),"scene"]
    ]
    handles = [
        Rectangle((0,0),1,1, color = [v/255 for v in c]) for k,c,n in legend_data
    ]
    labels = [n for k,c,n in legend_data]


    # Show image
    plt.grid(False)
    plt.axis('off')
    plt.legend(handles,labels)
    plt.show()

    return mask



def evaluate(eval_path, mask):
    """Evaluate 'mask' with mask located in 'eval_path'. The function calculates TP, FP, TN, FN. Water pixels must be labeled as RGB (0,0,0) in mask located in 'eval_path'.

    Parameters
    ----------
    eval_path : str
        Path to evaluation mask
    mask : array_like
        Segmentation mask to evaluate

    Returns
    -------
    TP : int
        True positives
    FP : int
        False positives
    TN : int
        True negatives
    FN : int
        False negatives

    """

    # Load evaluation mask
    eval_mask = cv2.imread(eval_path)
    eval_mask = cv2.cvtColor(eval_mask, cv2.COLOR_BGR2RGB)

    c = (0,0,0) # Black
    indices = np.where(np.all(eval_mask == c, axis=-1))
    water_GT = list(zip(indices[0], indices[1]))
    
    indices = np.where(np.any(eval_mask != c, axis=-1))
    not_water_GT = list(zip(indices[0], indices[1]))

    TP = 0
    FP = 0
    TN = 0
    FN = 0

    for p in water_GT:
        if mask[p[0],p[1],:].tolist() == list(LIGHT_PURPLE):
            TP +=1 
        else:
            FN +=1
    
    for p in not_water_GT:
        if mask[p[0],p[1],:].tolist() != list(LIGHT_PURPLE):
            TN +=1
        else:
            FP +=1
    
    return TP, FP, TN, FN

